{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ac0e04",
   "metadata": {},
   "source": [
    "\n",
    "# Bayesian Treatment of Correlated Efficiencies\n",
    "\n",
    "This notebook complements the frequentist analysis presented in the README by examining the same problem from a Bayesian perspective. \n",
    "\n",
    "We consider the same multinomial model for the joint outcomes of two selections A and B, and focus on inference for the efficiency difference $\\Delta = p_{10} - p_{01}$.\n",
    "\n",
    "Rather than validating an uncertainty estimator via repeated sampling, we treat the underlying outcome probabilities $(p_{11}, p_{10}, p_{01}, p_{00})$ as random variables and infer their posterior distribution given observed counts.\n",
    "\n",
    "---\n",
    "\n",
    "## Model\n",
    "\n",
    "We assume:\n",
    "- A multinomial likelihood for the observed counts\n",
    "  $$\n",
    "  (n_{11}, n_{10}, n_{01}, n_{00}) \\sim \\mathrm{Multinomial}(N, \\mathbf{p})\n",
    "  $$\n",
    "\n",
    "- A Dirichlet prior on $\\mathbf{p}$. We adopt a symmetric $Dirichlet(1,1,1,1)$ prior, corresponding to a uniform prior over joint outcome probabilities. For the large sample sizes considered here, posterior results are insensitive to this choice.\n",
    "\n",
    "\n",
    "This conjugate choice allows direct sampling from the posterior distribution of $\\mathbf{p}$, from which derived quantities such as $\\Delta$ can be computed.\n",
    "\n",
    "---\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The aim of this notebook is to:\n",
    "- obtain the posterior distribution of $\\Delta$,\n",
    "- compare Bayesian credible intervals with the frequentist uncertainty validated previously,\n",
    "- and verify that both approaches are driven by the same disagreement structure.\n",
    "\n",
    "This analysis is intended as a consistency check and alternative interpretation, not as a replacement for the frequentist results.\n",
    "\n",
    "No hypothesis testing or decision rules are imposed; results are reported as posterior summaries.\n",
    "\n",
    "### What the Bayesian approach adds\n",
    "\n",
    "Compared to the frequentist treatment, the Bayesian framework provides:\n",
    "- a full posterior distribution for the efficiency difference $\\Delta$,\n",
    "- direct probability statements such as $P(\\Delta>0)$,\n",
    "- and a natural treatment of small-sample regimes where asymptotic approximations may be unreliable.\n",
    "\n",
    "For large data samples, the Bayesian posterior width agrees with the frequentist uncertainty derived previously, confirming the consistency of both approaches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1a1a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import bayes_delta_posterior\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "# Load local configuration file\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "seed = cfg[\"seed\"]\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "p = cfg[\"p_true\"]\n",
    "p_true = np.array([p[\"p11\"], p[\"p10\"], p[\"p01\"], p[\"p00\"]], dtype=float)\n",
    "Npost=500000\n",
    "Ns = [1, 10, 100, 1000, 10000, 100000, 1000000]\n",
    "alpha_prior = np.array(cfg.get(\"alpha_prior\", [1,1,1,1]),dtype=float)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for N in Ns:\n",
    "    Delta_samples, info = bayes_delta_posterior(N, p_true, rng, alpha_prior=alpha_prior, Npost=Npost)\n",
    "\n",
    "    plt.hist(\n",
    "        Delta_samples,\n",
    "        bins=120,\n",
    "        density=True,\n",
    "        histtype=\"step\",\n",
    "        linewidth=2,\n",
    "        label=rf\"$N={N:,}$, $\\sigma_\\Delta={np.std(Delta_samples):.3e}$\"\n",
    "    )\n",
    "    print(f\"N={N}: counts =\", info['n'])\n",
    "    print(\"- P(Delta > 0) =\", np.mean(Delta_samples > 0))\n",
    "\n",
    "plt.xlabel(r\"$\\Delta = p_{10} - p_{01}$\")\n",
    "plt.ylabel(\"Posterior density\")\n",
    "plt.title(r\"Bayesian posterior for $\\Delta$ with different $N_{{observed}}=N$\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5711668a",
   "metadata": {},
   "source": [
    "The above plot showed that as the observations increase, the posterior becomes more narrow and centered around the true value. \n",
    "\n",
    "### Posterior probability of improvement\n",
    "\n",
    "From the posterior samples, we compute the probability that method A outperforms method B,\n",
    "\n",
    "$$P(\\Delta > 0 \\mid \\text{data})$$\n",
    "\n",
    "As the number of observed events increases, this probability rapidly approaches 1, reflecting increasing certainty that the efficiency of A exceeds that of B. This provides a direct probabilistic statement that is not available in a frequentist hypothesis-testing framework.\n",
    "\n",
    "\n",
    "One interesting result is obtained when one checks the scaling of $\\sigma$ with the $N$ as well as the 68% credible intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "means, sigmas = [], []\n",
    "q16s, q50s, q84s = [], [], []\n",
    "\n",
    "for N in Ns:\n",
    "    Delta_samples, _ = bayes_delta_posterior(N, p_true, rng, alpha_prior=alpha_prior, Npost=Npost)\n",
    "    means.append(np.mean(Delta_samples))\n",
    "    sigmas.append(np.std(Delta_samples))\n",
    "    q16, q50, q84 = np.quantile(Delta_samples, [0.16, 0.5, 0.84])\n",
    "    q16s.append(q16)\n",
    "    q50s.append(q50)\n",
    "    q84s.append(q84)\n",
    "sigmas = np.array(sigmas)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(Ns, sigmas, marker=\"o\", label=\"Posterior std from samples\")\n",
    "\n",
    "# expected scaling ~ sqrt((p10+p01)/N)\n",
    "p10, p01 = p_true[1], p_true[2]\n",
    "expected = np.sqrt((p10 + p01) / np.array(Ns))\n",
    "plt.plot(Ns, expected, marker=\"o\", linestyle=\"--\", label=r\"Expected $\\sqrt{(p_{10}+p_{01})/N}$\")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"N (number of events)\")\n",
    "plt.ylabel(r\"$\\sigma_\\Delta$\")\n",
    "plt.title(r\"Posterior uncertainty scales as $1/\\sqrt{N}$\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.errorbar(Ns, means, yerr=sigmas, linestyle=\"-\", marker=\"o\", color='black', label=\"Posterior means ± std\")\n",
    "#plt.plot(Ns, means, linestyle=\"-\",marker=\"o\",color='black', label=\"Posterior means\")\n",
    "plt.plot(Ns, q50s, linestyle=\"-\", color='blue', label=\"Posterior median\")\n",
    "plt.fill_between(Ns, q16s, q84s, alpha=0.3, label=\"68% credible interval\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"N\")\n",
    "plt.ylabel(r\"$\\Delta$\")\n",
    "plt.title(\"Posterior contraction with increasing N\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c9751e",
   "metadata": {},
   "source": [
    "And we can derive the statistics for $\\Delta$ from its posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd21918",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "Delta_samples, info = bayes_delta_posterior(N, p_true, rng, alpha_prior=alpha_prior, Npost=Npost)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(Delta_samples, bins=100, histtype='stepfilled', alpha=0.7, label='Delta Distribution')\n",
    "plt.xlabel(r'$\\Delta = e_A - e_B$ ')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.title(rf'Efficiency Difference (Bayesian Posterior)') \n",
    "plt.show()\n",
    "\n",
    "print(\"Bayes Method Results:\")\n",
    "print(\"Delta Mean and Std Dev from Posterior Samples:\")\n",
    "print(\"Mean:\", np.mean(Delta_samples))\n",
    "print(\"Std Dev:\", np.std(Delta_samples))\n",
    "print(\"P(Delta > 0) =\", np.mean(Delta_samples > 0))\n",
    "print(f\"68% credible interval:\", np.quantile(Delta_samples, [0.16, 0.84]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb11aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea54a7d5",
   "metadata": {},
   "source": [
    "## Discussion and Conclusions\n",
    "\n",
    "Using a Dirichlet–multinomial model, we obtained the full posterior distribution of the joint outcome probabilities\n",
    "\n",
    "$$(p_{11}, p_{10}, p_{01}, p_{00}) \\mid (n_{11}, n_{10}, n_{01}, n_{00}),$$\n",
    "\n",
    "which remains Dirichlet (due to conjugacy).\n",
    "\n",
    "From this posterior, we derived the induced distribution of the efficiency difference $\\Delta = p_{10} - p_{01}$ by direct sampling.\n",
    "\n",
    "Several observations follow:\n",
    "\n",
    "- Posterior uncertainty in $\\Delta$ is driven entirely by disagreement probabilities $p_{10}$ and $p_{01}$, mirroring the frequentist result that only disagreement events contribute to the variance of $\\hat\\Delta$.\n",
    "- Concordant outcomes ($p_{11}$ and $p_{00}$) affect the posterior normalization but do not contribute to the spread of $\\Delta$.\n",
    "- In the large-sample limit, Bayesian credible intervals for $\\Delta$ agree with the frequentist uncertainty estimate validated via toy Monte Carlo in the main analysis.\n",
    "\n",
    "This confirms that the frequentist variance estimator derived previously is consistent with the Bayesian posterior spread under a conjugate prior, and that both frameworks encode the same underlying information structure.\n",
    "\n",
    "The Bayesian approach provides a complementary interpretation, enabling direct probability statements about $\\Delta$ while leaving the core statistical conclusions unchanged. For large samples, the Bayesian posterior standard deviation of $\\Delta$ matches the frequentist uncertainty $\\sigma_{{Correct}}$ derived previously, confirming that both approaches encode the same information in different languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0310d5f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8405fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "def make_comparison_table(\n",
    "    Ns,\n",
    "    p_true,\n",
    "    rng,\n",
    "    alpha_prior=None,\n",
    "    Npost=200_000\n",
    "):\n",
    "    if alpha_prior is None:\n",
    "        alpha_prior = np.ones(4)\n",
    "\n",
    "    rows = []\n",
    "    p_true = np.asarray(p_true, dtype=float)\n",
    "\n",
    "    for N in Ns:\n",
    "        # \"Observed\" data (toy dataset)\n",
    "        n11, n10, n01, n00 = rng.multinomial(N, p_true)\n",
    "\n",
    "        # Frequentist quantities\n",
    "        Delta_hat = (n10 - n01) / N\n",
    "        sigma_corr = np.sqrt((n10 + n01) / (N**2))\n",
    "\n",
    "        Z = Delta_hat / sigma_corr if sigma_corr > 0 else np.nan\n",
    "        p_one_sided = 1 - norm.cdf(Z) if np.isfinite(Z) else np.nan\n",
    "        p_two_sided = 2 * (1 - norm.cdf(abs(Z))) if np.isfinite(Z) else np.nan\n",
    "\n",
    "        # Bayesian posterior\n",
    "        alpha_post = alpha_prior + np.array([n11, n10, n01, n00], dtype=float)\n",
    "        p_samp = rng.dirichlet(alpha_post, size=Npost)\n",
    "        Delta_post = p_samp[:, 1] - p_samp[:, 2]\n",
    "\n",
    "        post_mean = float(np.mean(Delta_post))\n",
    "        post_std  = float(np.std(Delta_post))\n",
    "        q16, q50, q84 = np.quantile(Delta_post, [0.16, 0.5, 0.84])\n",
    "        q025, q975 = np.quantile(Delta_post, [0.025, 0.975])\n",
    "        prob_gt0 = float(np.mean(Delta_post > 0))\n",
    "\n",
    "        rows.append({\n",
    "            \"N\": N,\n",
    "            \"n11\": int(n11), \"n10\": int(n10), \"n01\": int(n01), \"n00\": int(n00),\n",
    "            \"Delta_hat\": Delta_hat,\n",
    "            \"sigma_corr\": sigma_corr,\n",
    "            \"Z\": Z,\n",
    "            \"p_one_sided(H0:Δ=0)\": p_one_sided,\n",
    "            \"p_two_sided(H0:Δ=0)\": p_two_sided,\n",
    "            \"Bayes_mean(Δ)\": post_mean,\n",
    "            \"Bayes_std(Δ)\": post_std,\n",
    "            \"Bayes_CI68_low\": float(q16),\n",
    "            \"Bayes_median\": float(q50),\n",
    "            \"Bayes_CI68_high\": float(q84),\n",
    "            \"Bayes_CI95_low\": float(q025),\n",
    "            \"Bayes_CI95_high\": float(q975),\n",
    "            \"Bayes_P(Δ>0)\": prob_gt0,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Optional: nicer formatting for display\n",
    "    return df\n",
    "\n",
    "seed = cfg[\"seed\"]\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "Ns = [10, 100, 1000, 10000, 100000]\n",
    "\n",
    "df = make_comparison_table(Ns, p_true, rng, alpha_prior=alpha_prior, Npost=Npost)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d58b7a9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
